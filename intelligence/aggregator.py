"""
Aggregator â€” Processes scan results, discovers new signature candidates,
and updates the RASP signatures YAML.

Reads scanner output JSON and:
1. Validates findings against existing signatures
2. Identifies new co-occurring patterns not in the database
3. Generates an updated rasp-signatures.yaml with new entries

Usage:
    python aggregator.py --results results/scan_results.json --signatures ../config/rasp-signatures.yaml
"""

from __future__ import annotations

import json
import sys
from collections import Counter
from pathlib import Path

import yaml


def load_scan_results(results_path: Path) -> list[dict]:
    with open(results_path) as f:
        return json.load(f)


def load_signatures(sig_path: Path) -> dict:
    with open(sig_path) as f:
        return yaml.safe_load(f)


def analyze_distribution(results: list[dict]) -> dict:
    """Compute vendor distribution and indicator frequency."""
    vendor_counts: Counter = Counter()
    indicator_counts: Counter = Counter()
    vendor_indicators: dict[str, set[str]] = {}

    for result in results:
        for vendor in result.get("vendors", []):
            vendor_counts[vendor] += 1

        for hit in result.get("hits", []):
            vendor = hit["vendor"]
            indicator = f"{hit['layer']}:{hit['indicator']}"
            indicator_counts[indicator] += 1

            if vendor not in vendor_indicators:
                vendor_indicators[vendor] = set()
            vendor_indicators[vendor].add(indicator)

    return {
        "total_samples": len(results),
        "rasp_detected": len(results),
        "vendor_counts": dict(vendor_counts.most_common()),
        "top_indicators": dict(indicator_counts.most_common(50)),
        "vendor_indicators": {k: sorted(v) for k, v in vendor_indicators.items()},
    }


def discover_new_signatures(
    results: list[dict],
    existing_signatures: dict,
    min_occurrences: int = 20,
) -> list[dict]:
    """Find indicator patterns not covered by existing signatures."""
    known_vendors = set(existing_signatures.get("signatures", {}).keys())

    # Collect indicators for unknown vendors
    unknown_indicators: Counter = Counter()
    unknown_details: dict[str, list[str]] = {}

    for result in results:
        for hit in result.get("hits", []):
            if hit["vendor"] not in known_vendors:
                key = f"{hit['layer']}:{hit['indicator']}"
                unknown_indicators[key] += 1
                if key not in unknown_details:
                    unknown_details[key] = []
                if len(unknown_details[key]) < 5:
                    unknown_details[key].append(hit.get("detail", ""))

    # Filter by minimum occurrence threshold
    candidates = []
    for indicator, count in unknown_indicators.most_common():
        if count < min_occurrences:
            break
        candidates.append({
            "indicator": indicator,
            "count": count,
            "examples": unknown_details.get(indicator, []),
        })

    return candidates


def generate_report(analysis: dict, candidates: list[dict]) -> str:
    """Generate a human-readable intelligence report."""
    lines = [
        "# Sentinellium Intelligence Report",
        "",
        f"**Samples analyzed:** {analysis['total_samples']}",
        f"**RASP detected in:** {analysis['rasp_detected']} samples",
        "",
        "## Vendor Distribution",
        "",
        "| Vendor | Count | % of RASP samples |",
        "|--------|-------|-------------------|",
    ]

    total = analysis["rasp_detected"] or 1
    for vendor, count in analysis["vendor_counts"].items():
        pct = count / total * 100
        lines.append(f"| {vendor} | {count} | {pct:.1f}% |")

    if candidates:
        lines.extend([
            "",
            "## New Signature Candidates",
            "",
            "Patterns not in current database with significant occurrence:",
            "",
            "| Indicator | Count | Examples |",
            "|-----------|-------|----------|",
        ])
        for c in candidates:
            examples = ", ".join(c["examples"][:3])
            lines.append(f"| `{c['indicator']}` | {c['count']} | {examples} |")

    lines.extend([
        "",
        "---",
        "*Generated by Sentinellium Intelligence Pipeline*",
    ])

    return "\n".join(lines)


def main() -> None:
    import argparse

    parser = argparse.ArgumentParser(description="RASP intelligence aggregator")
    parser.add_argument("--results", required=True, help="Path to scan_results.json")
    parser.add_argument("--signatures", default="../config/rasp-signatures.yaml", help="Existing signatures YAML")
    parser.add_argument("--min-occurrences", type=int, default=20, help="Min occurrences for new candidates")
    parser.add_argument("--report", default="results/intelligence_report.md", help="Output report path")
    args = parser.parse_args()

    results = load_scan_results(Path(args.results))
    signatures = load_signatures(Path(args.signatures))

    analysis = analyze_distribution(results)
    candidates = discover_new_signatures(results, signatures, args.min_occurrences)

    # Print summary
    print(f"[aggregator] Analyzed {analysis['total_samples']} samples")
    print(f"[aggregator] Vendors found: {len(analysis['vendor_counts'])}")
    print(f"[aggregator] New candidates: {len(candidates)}")

    for vendor, count in analysis["vendor_counts"].items():
        print(f"  {vendor}: {count}")

    # Write report
    report = generate_report(analysis, candidates)
    report_path = Path(args.report)
    report_path.parent.mkdir(parents=True, exist_ok=True)
    with open(report_path, "w") as f:
        f.write(report)
    print(f"[aggregator] Report written to {report_path}")

    # Write raw analysis JSON
    analysis_path = report_path.parent / "analysis.json"
    with open(analysis_path, "w") as f:
        json.dump(analysis, f, indent=2)


if __name__ == "__main__":
    main()
